{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmdkS2Lh84o0"
      },
      "source": [
        "Katie Mears"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igj_aSvf8lcC"
      },
      "source": [
        "# Naive Bayes on Political Text\n",
        "\n",
        "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xMGR503L8lcE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\katie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\katie\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import os\n",
        "from string import punctuation\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "# Feel free to include your text patterns functions\n",
        "#from text_functions_solutions import clean_tokenize, get_patterns\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load English stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCbF7GOcEK57"
      },
      "source": [
        "# Mount Drive and Changing Working Directory, Confirm DB is in WD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyGf1CMLDcIF",
        "outputId": "c691e4c1-6e5a-4efe-928a-aeda4e2e6466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Working Directory: C:\\Users\\katie\\OneDrive\\Documents\\ADS509_Assignment4_Repo\n"
          ]
        }
      ],
      "source": [
        "os.chdir('C:/Users/katie/OneDrive/Documents/ADS509_Assignment4_Repo')\n",
        "print(\"Current Working Directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOGP-qAZDK8c",
        "outputId": "a3a1ec0a-ebcc-4255-d2d1-a09de2a5e746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Does the database file exist? True\n"
          ]
        }
      ],
      "source": [
        "# Verify if the database file exists\n",
        "db_file = \"2020_Conventions.db\"\n",
        "print(\"Does the database file exist?\", os.path.isfile(db_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k4oy8CF08lcF"
      },
      "outputs": [],
      "source": [
        "convention_db = sqlite3.connect(\"C:/Users/katie/OneDrive/Documents/ADS509_Assignment4_Repo/2020_Conventions.db\")\n",
        "convention_cur = convention_db.cursor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu0ONIYh8lcF"
      },
      "source": [
        "## 1. Exploratory Naive Bayes\n",
        "\n",
        "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text\n",
        "for each party and prepare it for use in Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('conventions',)]\n"
          ]
        }
      ],
      "source": [
        "# List all tables in the database\n",
        "tables = convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
        "print(tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0, 'party', 'TEXT', 0, None, 0)\n",
            "(1, 'night', 'INTEGER', 0, None, 0)\n",
            "(2, 'speaker', 'TEXT', 0, None, 0)\n",
            "(3, 'speaker_count', 'INTEGER', 0, None, 0)\n",
            "(4, 'time', 'TEXT', 0, None, 0)\n",
            "(5, 'text', 'TEXT', 0, None, 0)\n",
            "(6, 'text_len', 'TEXT', 0, None, 0)\n",
            "(7, 'file', 'TEXT', 0, None, 0)\n"
          ]
        }
      ],
      "source": [
        "# View Scema of conventions table\n",
        "schema = convention_cur.execute(\"PRAGMA table_info(conventions);\").fetchall()\n",
        "for column in schema:\n",
        "    print(column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Democratic', 4, 'Unknown', 1, '00:00', 'Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', '127', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
            "('Democratic', 4, 'Speaker 1', 1, '00:33', 'I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. We’ve called the 48th Quadrennial Democratic National Convention to order.', '41', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
            "('Democratic', 4, 'Speaker 2', 1, '00:59', 'Every four years, we come together to reaffirm our democracy. This year, we’ve come to save it.', '17', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
            "('Democratic', 4, 'Kerry Washington', 1, '01:07', 'We fight for a more perfect union because we are fighting for the soul of this country and for our lives. And right now that fight is real.', '28', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
            "('Democratic', 4, 'Bernie Sanders', 1, '01:18', 'We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.', '22', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n"
          ]
        }
      ],
      "source": [
        "# View Sample of the data \n",
        "convention_cur.execute(\"SELECT * FROM conventions LIMIT 5;\")\n",
        "rows = convention_cur.fetchall()\n",
        "for row in rows:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "7c_mztRE8lcG",
        "outputId": "34b68b66-0d8b-49fb-b166-477737db527a"
      },
      "outputs": [],
      "source": [
        "convention_data = []\n",
        "\n",
        "# fill the above list up with items that are themselves lists. The\n",
        "# sublists will have two elements. The first element in the sublist\n",
        "# should be the speech in a single string. The second element\n",
        "# of the sublist should be the party.\n",
        "\n",
        "query_results = convention_cur.execute(\n",
        "                            '''\n",
        "                            SELECT text, party \n",
        "                            FROM conventions\n",
        "                            WHERE party != 'Other';\n",
        "                            ''')\n",
        "\n",
        "for row in query_results :\n",
        "    # store the results in convention_data\n",
        "    speech, party = row\n",
        "    convention_data.append([speech, party])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text       party\n",
            "0  Skip to content The Company Careers Press Free...  Democratic\n",
            "1  I’m here by calling the full session of the 48...  Democratic\n",
            "2  Every four years, we come together to reaffirm...  Democratic\n",
            "3  We fight for a more perfect union because we a...  Democratic\n",
            "4  We must come together to defeat Donald Trump, ...  Democratic\n"
          ]
        }
      ],
      "source": [
        "# Convert to DataFrame\n",
        "df_convention = pd.DataFrame(convention_data, columns=['text', 'party'])\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df_convention.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y0G-e3g08lcG"
      },
      "outputs": [],
      "source": [
        "# it's a best practice to close up your DB connection when you're done\n",
        "convention_db.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os3Iqo7U8lcG"
      },
      "source": [
        "Let's look at some random entries and see if they look right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gKmJYmGl8lcG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['We need a president who stands up for America, not one who takes a knee. A strong and proud America is a safe America, safe from our enemies and safe from war. No one who’s seen the face of war desires to see it again. Too many of our fellow Americans or already honored at the hallowed grounds of Arlington. But if we want peace, we must be strong. Weakness is provocative. President Trump’s strength has kept us out of war. Joe Biden won’t stand up for America. Donald Trump will. So this November let’s stand with the President and vote to keep America great.',\n",
              "  'Republican'],\n",
              " ['Our military is now better equipped, better resourced and better manned than any military in the world. President Trump demolished the terrorist ISIS caliphate in the Middle East and eliminated its leader, al-Baghdadi, one of the world’s most brutal terrorists. President Trump took decisive action against Iranian terrorist mastermind, Qasem Soleimani, a man responsible for deaths of hundreds of American service men in Iraq. When our NATO allies failed to meet their commitments, as we upheld ours, President Trump demanded parody. NATO members have now increased their contributions over $100 billion this year, and NATO’s secretary general credits President Donald J. Trump.',\n",
              "  'Republican'],\n",
              " ['And what also moved me about Joe is the work that he did as he was going back and forth. This is the leader who wrote the Violence Against Women Act, and enacted the Assault Weapons Ban. Who as vice president implemented the Recovery Act, which brought our country back from the great recessions. He championed the Affordable Care Act protecting millions of Americans with preexisting conditions, who spent decades promoting American values and interests around the world.',\n",
              "  'Democratic'],\n",
              " ['The radical left has taken over the democratic party, and Joe Biden is marching in lock step with them. Biden and the far left are promising to crush middle class families with trillions in new taxes.',\n",
              "  'Republican'],\n",
              " ['That I will bear arms.', 'Republican']]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random.choices(convention_data,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXgTKVqp8lcG"
      },
      "source": [
        "It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AGH5zw-38lcG"
      },
      "outputs": [],
      "source": [
        "conv_sent_data = []\n",
        "\n",
        "# Define a regular expression pattern for sentence splitting\n",
        "sentence_pattern = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\!|\\?)(\\s)'\n",
        "\n",
        "for speech, party in convention_data :\n",
        "    sentences = re.split(sentence_pattern, speech)\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()  \n",
        "        if sentence:  \n",
        "            conv_sent_data.append([sentence, party])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMoAJOOr8lcG"
      },
      "source": [
        "Again, let's look at some random entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0voXKYF_8lcG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['I’ve said from the outset of this election that we’re in the battle for the soul of this nation.',\n",
              "  'Democratic'],\n",
              " ['When the field was clear for him to run for the Senate, he chose to finish his job as AG instead.',\n",
              "  'Democratic'],\n",
              " ['In North Korea, the president lowered the temperature and against all odds got the North Korean leadership to the table.',\n",
              "  'Republican'],\n",
              " ['Providing unyielding support for our troops, combating crime and violence against women, leading our quest to cure cancer and safeguarding the landmark American recovery and Reinvestment Act from corruption.',\n",
              "  'Democratic'],\n",
              " ['Imagine what we could achieve.', 'Democratic']]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random.choices(conv_sent_data,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr2Zwxd08lcG"
      },
      "source": [
        "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps:\n",
        "\n",
        "1. Tokenize on whitespace\n",
        "1. Remove punctuation\n",
        "1. Remove tokens that fail the `isalpha` test\n",
        "1. Remove stopwords\n",
        "1. Casefold to lowercase\n",
        "1. Join the remaining tokens into a string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v0BhKHt78lcG",
        "outputId": "db3d04ef-2dc0-4ca5-d89e-956bb2d565b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('work believe goodness america promise men women created equal watching tonight betting',\n",
              "  'Republican'),\n",
              " ('yet every often pace various generations compelled resurrect give rebirth providential beginning renew present days exuberance founding days',\n",
              "  'Republican'),\n",
              " ('make america safe', 'Republican'),\n",
              " ('going talk something close heart', 'Democratic'),\n",
              " ('result seen smallest economic contraction major western nation recovering much faster rate anybody',\n",
              "  'Republican')]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_conv_sent_data = [] # list of tuples (sentence, party), with sentence cleaned\n",
        "\n",
        "for idx, sent_party in enumerate(conv_sent_data) :\n",
        "    sentence, party = sent_party\n",
        "    tokens = sentence.split()\n",
        "    tokens = [\n",
        "        token.strip(string.punctuation)\n",
        "        for token in tokens \n",
        "        if token.strip(string.punctuation).isalpha()]\n",
        "    tokens = [token \n",
        "        for token in tokens \n",
        "        if token.lower() not in stop_words]\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "    cleaned_sentence = ' '.join(tokens)\n",
        "    clean_conv_sent_data.append((cleaned_sentence, party))\n",
        "\n",
        "random.choices(clean_conv_sent_data,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNesxxo_8lcH"
      },
      "source": [
        "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rA_ah9J_8lcH",
        "outputId": "709d5bfd-1b97-4f1c-9d27-b803f0d07cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With a word cutoff of 5, we have 2239 as features in the model.\n"
          ]
        }
      ],
      "source": [
        "word_cutoff = 5\n",
        "\n",
        "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
        "\n",
        "word_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "feature_words = set()\n",
        "\n",
        "for word, count in word_dist.items() :\n",
        "    if count > word_cutoff :\n",
        "        feature_words.add(word)\n",
        "\n",
        "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TLyN7PuU8lcH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def conv_features(text,fw) :\n",
        "    \"\"\"Given some text, this returns a dictionary holding the\n",
        "       feature words.\n",
        "\n",
        "       Args:\n",
        "            * text: a piece of text in a continuous string. Assumes\n",
        "            text has been cleaned and case folded.\n",
        "            * fw: the *feature words* that we're considering. A word\n",
        "            in `text` must be in fw in order to be returned. This\n",
        "            prevents us from considering very rarely occurring words.\n",
        "\n",
        "       Returns:\n",
        "            A dictionary with the words in `text` that appear in `fw`.\n",
        "            Words are only counted once.\n",
        "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
        "            then this would return a dictionary of\n",
        "            {'quick' : True,\n",
        "             'fox' :    True}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ret_dict = {}\n",
        "\n",
        "    for word in set(text.split()):\n",
        "        if word in fw:\n",
        "            ret_dict[word] = True\n",
        "\n",
        "    return(ret_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Osjy_FgK8lcH"
      },
      "outputs": [],
      "source": [
        "assert(len(feature_words)>0)\n",
        "assert(conv_features(\"obama was the president\",feature_words)==\n",
        "       {'obama':True,'president':True})\n",
        "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
        "                     {'people':True,'america':True,\"citizens\":True})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjIbgZhV8lcH"
      },
      "source": [
        "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "crvMZN4g8lcH"
      },
      "outputs": [],
      "source": [
        "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CydMi3t_8lcH"
      },
      "outputs": [],
      "source": [
        "random.seed(20220507)\n",
        "random.shuffle(featuresets)\n",
        "\n",
        "test_size = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "boTHa8T98lcI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.498\n"
          ]
        }
      ],
      "source": [
        "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NTZAkksg8lcI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
            "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
            "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
            "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
            "                supports = True           Republ : Democr =     16.1 : 1.0\n",
            "                   media = True           Republ : Democr =     15.9 : 1.0\n",
            "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
            "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
            "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
            "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
            "                 private = True           Republ : Democr =     11.9 : 1.0\n",
            "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
            "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
            "                 special = True           Republ : Democr =     10.3 : 1.0\n",
            "                   trade = True           Republ : Democr =     10.0 : 1.0\n",
            "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
            "                   local = True           Republ : Democr =      9.9 : 1.0\n",
            "                 allowed = True           Republ : Democr =      9.7 : 1.0\n",
            "                   elect = True           Democr : Republ =      9.6 : 1.0\n",
            "                   moved = True           Republ : Democr =      9.0 : 1.0\n",
            "                   bless = True           Republ : Democr =      9.0 : 1.0\n",
            "                    land = True           Republ : Democr =      8.9 : 1.0\n",
            "                  agenda = True           Republ : Democr =      8.8 : 1.0\n",
            "               countries = True           Republ : Democr =      8.8 : 1.0\n",
            "                   crime = True           Republ : Democr =      8.8 : 1.0\n"
          ]
        }
      ],
      "source": [
        "classifier.show_most_informative_features(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAo0oIGw8lcI"
      },
      "source": [
        "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
        "\n",
        "### My Observations\n",
        "\n",
        "It is interesting to see which features are mentioned by which party more often. Words like enforcement, destroy and media are all words that seems to be more prevalent in Republican speeches compared to Democrats. On the other hand, words like climate and votes were spoken more often than in Republican speeches. It is also interesting that the Republican speech's mentioned most of these words more often than Democrats in general as 22/25 features were spoken more frequently in Republican speeches compared to Democrat speeches.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233GnRTU8lcI"
      },
      "source": [
        "## Part 2: Classifying Congressional Tweets\n",
        "\n",
        "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
        "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
        "give you the query I used to pull out the tweets. Note that this DB has some big tables and\n",
        "is unindexed, so the query takes a minute or two to run on my machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "t1-3i3fr8lcI"
      },
      "outputs": [],
      "source": [
        "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
        "cong_cur = cong_db.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vgU7r_1B8lcI"
      },
      "outputs": [],
      "source": [
        "results = cong_cur.execute(\n",
        "        '''\n",
        "           SELECT DISTINCT\n",
        "                  cd.candidate,\n",
        "                  cd.party,\n",
        "                  tw.tweet_text\n",
        "           FROM candidate_data cd\n",
        "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle\n",
        "               AND cd.candidate == tw.candidate\n",
        "               AND cd.district == tw.district\n",
        "           WHERE cd.party in ('Republican','Democratic')\n",
        "               AND tw.tweet_text NOT LIKE '%RT%'\n",
        "        ''')\n",
        "\n",
        "results = list(results) # Just to store it, since the query is time consuming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NavW3Lm58lcI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq', 'Republican'], [b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6', 'Republican'], [b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA', 'Republican'], [b'\"The trouble with Socialism is that eventually you run out of other people\\'s money.\" - Margaret Thatcher https://t.co/X97g7wzQwJ', 'Republican'], [b'\"The trouble with socialism is eventually you run out of other people\\'s money\" \\xe2\\x80\\x93 Thatcher. She\\'ll be sorely missed. http://t.co/Z8gBnDQUh8', 'Republican']]\n"
          ]
        }
      ],
      "source": [
        "tweet_data = []\n",
        "\n",
        "for candidate, party, tweet_text in results:\n",
        "    tweet_data.append([tweet_text, party])  \n",
        "\n",
        "print(tweet_data[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxmTOVI38lcI"
      },
      "source": [
        "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pSnciCfy8lcI"
      },
      "outputs": [],
      "source": [
        "random.seed(20201014)\n",
        "\n",
        "tweet_data_sample = random.choices(tweet_data,k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast\n",
            "Actual party is Democratic and our classifier says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: go tribe rallytogether\n",
            "Actual party is Democratic and our classifier says Democratic.\n",
            "\n",
            "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget\n",
            "Actual party is Democratic and our classifier says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line\n",
            "Actual party is Republican and our classifier says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: make even greater kag\n",
            "Actual party is Republican and our classifier says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: cavs tie series im repbarbaralee scared roadtovictory\n",
            "Actual party is Democratic and our classifier says Democratic.\n",
            "\n",
            "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue\n",
            "Actual party is Democratic and our classifier says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: really close raised toward match right whoot nonmath majors room help us get httpstcoqsdqkypsmc\n",
            "Actual party is Democratic and our classifier says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: today comment period plan expand offshore drilling opened public days march share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
            "Actual party is Democratic and our classifier says Republican.\n",
            "\n",
            "Here's our (cleaned) tweet: celebrated years eastside commitment amp saluted community leaders last awards dinner\n",
            "Actual party is Democratic and our classifier says Republican.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to clean and tokenize text\n",
        "def clean_tokenize(text):\n",
        "    if isinstance(text, bytes):  \n",
        "        text = text.decode('utf-8')  \n",
        "    text = text.lower()  \n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) \n",
        "    tokens = text.split()  \n",
        "    cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]  \n",
        "    return ' '.join(cleaned_tokens) \n",
        "\n",
        "# Iterate over tweet data sample\n",
        "for tweet, party in tweet_data_sample:\n",
        "    cleaned_tweet = clean_tokenize(tweet)  \n",
        "    features = conv_features(cleaned_tweet, feature_words) \n",
        "    estimated_party = classifier.classify(features)  \n",
        "    \n",
        "    # Output the result\n",
        "    print(f\"Here's our (cleaned) tweet: {cleaned_tweet}\")\n",
        "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
        "    print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dictionary of counts by actual party and estimated party.\n",
        "# first key is actual, second is estimated\n",
        "parties = ['Republican','Democratic']\n",
        "results = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for p in parties :\n",
        "    for p1 in parties :\n",
        "        results[p][p1] = 0\n",
        "\n",
        "\n",
        "num_to_score = 10\n",
        "random.shuffle(tweet_data_sample)\n",
        "\n",
        "for idx, tp in enumerate(tweet_data_sample) :\n",
        "    tweet, party = tp\n",
        "    features = conv_features(tweet.lower(), feature_words) \n",
        "\n",
        "    # get the estimated party\n",
        "    estimated_party = classifier.classify(features)\n",
        "\n",
        "    results[party][estimated_party] += 1\n",
        "\n",
        "    if idx > num_to_score :\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>()>,\n",
              "            {'Republican': defaultdict(int,\n",
              "                         {'Republican': 0, 'Democratic': 2}),\n",
              "             'Democratic': defaultdict(int,\n",
              "                         {'Republican': 0, 'Democratic': 8})})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIb6bfVu8lcI"
      },
      "source": [
        "Now that we've looked at it some, let's score a bunch and see how we're doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8Qo-32Dy8lcI"
      },
      "outputs": [],
      "source": [
        "# dictionary of counts by actual party and estimated party.\n",
        "# first key is actual, second is estimated\n",
        "parties = ['Republican','Democratic']\n",
        "results = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for p in parties :\n",
        "    for p1 in parties :\n",
        "        results[p][p1] = 0\n",
        "\n",
        "\n",
        "num_to_score = 10000\n",
        "random.shuffle(tweet_data)\n",
        "\n",
        "for idx, tp in enumerate(tweet_data) :\n",
        "    tweet, party = tp\n",
        "    features = conv_features(tweet.lower(), feature_words) \n",
        "\n",
        "    # get the estimated party\n",
        "    estimated_party = classifier.classify(features)\n",
        "\n",
        "    results[party][estimated_party] += 1\n",
        "\n",
        "    if idx > num_to_score :\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_16QGBga8lcI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>()>,\n",
              "            {'Republican': defaultdict(int,\n",
              "                         {'Republican': 0, 'Democratic': 4278}),\n",
              "             'Democratic': defaultdict(int,\n",
              "                         {'Republican': 0, 'Democratic': 5724})})"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp5RTjVu8lcI"
      },
      "source": [
        "### Reflections\n",
        "\n",
        "The classification model classified every tweet to be democrat, which resulted in the misclassification of all 4278 Republican tweets. On the other hand, it correctly identified all 5724 Democrat tweets, never misclassifying any of them. The classification model had a low accuracy score of 49.8% which indicates that the model performance is very low and possibly biased towards one class, which was observed in the twitter data. This could be due to a class imbalance. I tried to look through the code for errors and couldnt find anything that jumped out at me as to why it would be classifying so poorly. Perhaps there is something wrong with how I cleaned and tokenized the data? I could not get the Punkt package to work even though I have it installed and it says its up to date. I tried to uninstall and reinstall and still had the same errors. To work around this, I used the string package instead. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
